---
title: "Longevity-Scilife"
output:
  bookdown::html_document2:
          toc: true
          toc_float: true
          toc_depth: 2
          number_sections: true
          theme: united
          highlight: tango
          df_print: paged
          code_folding: show
          self_contained: true
          keep_md: true
---

```{r,echo=FALSE,message=FALSE,warning=FALSE,results='hide'}
rm(list=ls())
library(knitr) # for markdown document
library(bookdown) # for markdown document
library(rmarkdown) # for markdown document

opts_knit$set(progress=TRUE,verbose=TRUE)
opts_chunk$set(dev="CairoPNG",results="hold",fig.show="hold",fig.align="center",
               echo=TRUE,warning=FALSE,message=FALSE)
```

```{r,message=FALSE,warning=FALSE}
library(DESeq2)
library(ggplot2)
library(ggrepel) # for non overlapping text on ggplot
source("functions.R")
```

## Data

The data is from Brain of Zebrafish. Data has been already low count filtered.

```{r,message=FALSE,warning=FALSE}
# read data
cdata <- read.delim("brain-counts.txt",header=T,sep="\t",stringsAsFactors=F,check.names=F)
mdata <- read.delim("brain-meta.txt",header=T,sep="\t",stringsAsFactors=F,check.names=F)
# keep only categorical data/remove numeric data
mdata <- mdata[,1:8]
head(cdata)
```

```{r,message=FALSE,warning=FALSE}
mdata
```

## Prepare model

```{r,message=FALSE,warning=FALSE}
# prepare model
model <- as.formula("~family+condition")

# convert metadata df to factors
temp <- as.data.frame(sapply(mdata,factor))
# set sat level as the lower level
temp$condition <- factor(as.character(temp$condition),levels=c("sat","lat"))

#visualise model matrix
model.matrix(model,temp)
```

## Create DESeq2 object

```{r,message=FALSE,warning=FALSE,fig.height=6,fig.width=6}
# prep DESeq2 object
ds1 <- DESeqDataSetFromMatrix(countData=cdata,colData=temp,design=model)
ds1$condition <- relevel(ds1$condition, ref="sat")
ds1 <- DESeq2::estimateSizeFactors(ds1,type="ratio")
ds1 <- DESeq2::estimateDispersions(ds1)
plotDispEsts(ds1)
```

## Visualise MDS plot

```{r,message=FALSE,warning=FALSE,fig.height=6,fig.width=6}
ds_vst <- as.data.frame(assay(varianceStabilizingTransformation(ds1,blind=F)),check.names=F)
# mds plot
# colvar can be any column from mdata
# head(mdata)
mdsplot(df=as.data.frame(t(ds_vst)),mdata,textlab="family",pointcol="rinbatch")
```

## Differential gene expression

```{r,message=FALSE,warning=FALSE,fig.height=6,fig.width=6}
# DGE
ds2 <- nbinomWaldTest(ds1)
#ds2 <- nbinomLRT(ds1,reduced=as.formula(~family))
resultsNames(ds2)
ds3 <- results(ds2,contrast=c("condition","sat","lat"),cooksCutoff=T,
                   independentFiltering=F,alpha=0.05,pAdjustMethod="BH")
print(summary(ds3))
```

## Questions

The general question I want to answer is which genes are differentially expressed between my two conditions SAT and LAT while controlling for batches such as family, extbatch etc.

Specific questions

1. Is it better to include a batch effect in the GLM model OR to
   correct the batch effect using SVA/Combat etc?

   Talked with multiple people abouth this and some seem to support
   the combat as better at taking care of these issues, whereas other
   really emphasised including the batch as a parameter in the
   model. The argument of the former was that he felt that blocking
   often had a too big of on impact so one was in essence
   over-compenstating. My take on this is that it will depend on the
   data analysed, just as with many other selections.

2. My batch correction using ComBat creates negative values. How do I deal with that?

   My take on this is that this should not happen


3. How do I include a continuous variable as a factor in my DESeq2 GLM
   model?

   Here I have no experience, but based on my reading of the DESeq2
   manual it seems they support the idea of clustering non-factor data
   into groups and then use these factor instead.


4. What is the diference between Wald's test and LRT test? How and
   which one do I use?

   It seems that in the majority of cases wald is the best test to
   use as it benefits of not having to include competing models, but
   that also means that the interpretation of the results are slighly
   different. Looking at the statistical side of it, the lrt should
   estimate the confidence interval with better precision and is hence
   "better", but it also more difficult to run since one have to fit
   two models.

5. How do I test which is a better model? ~family+condition or
   ~rinbatch+family+condition etc.

   Using lrt test you define a simpler and a more complex model and
   then you will find support for one or the other. I am however not
   sure you have enough data to include large number of entries as you
   then need to estimate lots of contrasts which is costly
   statistically.

6. How do I test for DEGs between my conditions? How do I find out if
   family has an effect or how much effect it has?

   If there were no impact of family you should not see any
   improvement in including family in the model. Given the structure
   in your data, I think it is clear that there is a large family
   effect. This is consistent with my previous experience where there
   often are strong impacts of family on the data.



```{r,message=FALSE,warning=FALSE,eval=FALSE,echo=FALSE,results="hide"}
rmarkdown::render("script.Rmd")
```

_End of Document_






